{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba589493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directoy is /home/mskang/hyeokjong/cancer/2019/custom_model\n",
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '0'\n",
    "#!pip install import_ipynb\n",
    "import import_ipynb\n",
    "\n",
    "if os.getcwd() != '/home/mskang/hyeokjong/cancer/2019/custom_model':\n",
    "    path = '/home/mskang/hyeokjong/cancer/2019/custom_model'\n",
    "    os.chdir('/home/mskang/hyeokjong/cancer/2019/custom_model')\n",
    "    print('directory changed !' )\n",
    "    print( 'current directoy is', str(os.getcwd()) )\n",
    "else:\n",
    "    print( 'current directoy is', str(os.getcwd()) )\n",
    "from data_224_128 import*\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataset import random_split\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0f13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class Interpolation(nn.Module):\n",
    "    def __init__(self, out_size):\n",
    "        super().__init__()\n",
    "        self.size = out_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.interpolate(x, size = self.size, mode = 'bilinear', align_corners = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2356647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class residual_block(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.resi =  nn.Sequential( nn.Conv2d(in_channels = in_channel, out_channels = out_channel, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                                    nn.BatchNorm2d(num_features = out_channel),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Conv2d(in_channels = out_channel, out_channels = out_channel, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                                    nn.BatchNorm2d(num_features = out_channel) )\n",
    "        \n",
    "        self.identity = nn.Sequential( nn.Conv2d(in_channels = in_channel, out_channels = out_channel, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                                    nn.BatchNorm2d(num_features = out_channel),\n",
    "                                    nn.ReLU())\n",
    "    def forward(self, x):\n",
    "        resi = self.resi(x)\n",
    "        identity = self.identity(x)\n",
    "        out = resi + identity\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75257873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class residual_block_con_connect(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.resi =  nn.Sequential( nn.Conv2d(in_channels = in_channel, out_channels = out_channel, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                                    nn.BatchNorm2d(num_features = out_channel),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Conv2d(in_channels = out_channel, out_channels = out_channel, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                                    nn.BatchNorm2d(num_features = out_channel) )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        resi = self.resi(x)\n",
    "        out = resi +x\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d38a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class att_resi(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.s = nn.Sigmoid()\n",
    "        self.resi =  nn.Sequential( nn.Conv2d(in_channels = in_channel, out_channels = out_channel, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                                    nn.BatchNorm2d(num_features = out_channel),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Conv2d(in_channels = out_channel, out_channels = out_channel, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                                    nn.BatchNorm2d(num_features = out_channel) )\n",
    "        self.conv_connect = nn.Sequential( nn.Conv2d(in_channels = in_channel, out_channels = out_channel, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "                                    nn.BatchNorm2d(num_features = out_channel),\n",
    "                                    nn.ReLU() )\n",
    "        self.conv = nn.Sequential( nn.Conv2d(in_channels = out_channel, out_channels = out_channel, kernel_size = 3, stride = 2, padding = 1, bias = False),\n",
    "                                    nn.BatchNorm2d(num_features = out_channel),\n",
    "                                    nn.ReLU() )\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        resi = self.resi(x)\n",
    "        out = resi + self.conv_connect(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv(out)\n",
    "        out = self.s(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6830df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention_naive(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.interpolation128 = Interpolation(128)\n",
    "        self.interpolation64 = Interpolation(64)\n",
    "        self.interpolation32 = Interpolation(32)\n",
    "        \n",
    "        \n",
    "        self.c1 = nn.Sequential( nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 1, stride = 1, padding = 0, bias = False),\n",
    "                                   nn.BatchNorm2d(num_features = 16),   \n",
    "                                   nn.ReLU())\n",
    "        self.c2 = nn.Sequential( nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 1, stride = 1, padding = 0, bias = False),\n",
    "                                   nn.BatchNorm2d(num_features = 32),   \n",
    "                                   nn.ReLU())\n",
    "        self.c3 = nn.Sequential( nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 1, stride = 1, padding = 0, bias = False),\n",
    "                                   nn.BatchNorm2d(num_features = 64),   \n",
    "                                   nn.ReLU())\n",
    "        \n",
    "        self.conv1 = self.make_residual_block_att(1, 3, 16) \n",
    "        self.conv2 = self.make_residual_block_att(1, 32, 32) \n",
    "        self.conv3 = self.make_residual_block_att(1, 64, 64) \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.att1 = self.make_residual_block_att(1, 3, 16) \n",
    "        self.att2 = self.make_residual_block_att(1, 16, 32) \n",
    "        self.att3 = self.make_residual_block_att(1, 32, 64)  \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.resi4_1 = self.make_residual_block(1, 128, 256) \n",
    "        self.resi4_2 = self.make_residual_block(1, 256, 256) \n",
    "        \n",
    "        self.resi5_1 = self.make_residual_block(1, 256, 256) \n",
    "        self.resi5_2 = self.make_residual_block(1, 256, 256) \n",
    "        self.resi5_3 = self.make_residual_block(1, 256, 512) \n",
    "        \n",
    "        self.resi6_1 = self.make_residual_block(1, 512, 512) \n",
    "        self.resi6_2 = self.make_residual_block(1, 512, 512) \n",
    "        self.resi6_3 = self.make_residual_block(1, 512, 1024) \n",
    "\n",
    "        self.Flatten = Flatten()\n",
    "        self.classifier = nn.Sequential( Flatten(),\n",
    "                                         nn.Linear(1024*4*4,1000),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Linear(1000, 8))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def make_residual_block(self, num_modules, in_channel, out_channel):\n",
    "        layers = list()\n",
    "        for i in range(num_modules):\n",
    "            if in_channel != out_channel:\n",
    "                layers.append(residual_block(in_channel, out_channel))\n",
    "            elif in_channel == out_channel:\n",
    "                layers.append(residual_block_con_connect(in_channel, out_channel))\n",
    "        return nn.Sequential( *layers )\n",
    "\n",
    "    \n",
    "    def make_residual_block_att(self, num_modules, in_channel, out_channel):\n",
    "        layers = list()\n",
    "        layers.append(att_resi(in_channel, out_channel))\n",
    "        \n",
    "        return nn.Sequential( *layers )\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, raw):   # 3 256\n",
    "        \n",
    "        raw1 = self.interpolation128(raw) # 3 128\n",
    "        raw2 = self.interpolation64(raw1) # 3 64\n",
    "        raw3 = self.interpolation32(raw2) # 3 32\n",
    "        \n",
    "        y = self.conv1(raw) # 16 128\n",
    "        \n",
    "        x = self.att1(raw) + 1 # 16 128\n",
    "        x = x*self.c1(raw1)    # 16 128\n",
    "        \n",
    "        y = torch.cat( (y,x), dim = 1 )\n",
    "\n",
    "        y = self.conv2(y)\n",
    "        \n",
    "        x = self.att2(x) + 1\n",
    "        x = x*self.c2(raw2)\n",
    "        \n",
    "        y = torch.cat( (y,x), dim = 1 )\n",
    "        y = self.conv3(y)\n",
    "        \n",
    "        x = self.att3(x) + 1\n",
    "        x = x*self.c3(raw3)\n",
    "        \n",
    "        y = torch.cat( (y,x), dim = 1 )\n",
    "\n",
    "        x = self.resi4_1(y)\n",
    "        x = self.resi4_2(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.resi5_1(x)\n",
    "        x = self.resi5_2(x)\n",
    "        x = self.resi5_3(x)\n",
    "        x = self.maxpool(x)        \n",
    "        \n",
    "        x = self.resi6_1(x)\n",
    "        x = self.resi6_2(x)\n",
    "        x = self.resi6_3(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25daa217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = attention_naive().to(device)\n",
    "path_model = '/home/mskang/hyeokjong/cancer/2019/custom_model/A_final_3.pt'\n",
    "model.load_state_dict(torch.load(path_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8a3303c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.041877, test accuracy: 98.83\n"
     ]
    }
   ],
   "source": [
    "def metric_function(output, target):\n",
    "    _, argmax = torch.max(output, dim = 1)\n",
    "    corrects = (argmax == target).sum()\n",
    "    return corrects \n",
    "\n",
    "running_loss = 0.0\n",
    "running_metric = 0.0\n",
    "loss_func = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "with torch.no_grad():       \n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "        \n",
    "    len_data_test = len(test_dl.dataset)\n",
    "            \n",
    "    for inputs, targets in test_dl:\n",
    "        inputs , targets = inputs.to(device) , targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "                \n",
    "        loss_batch = loss_func(outputs, targets)\n",
    "        metric_batch = metric_function(outputs, targets)\n",
    "                \n",
    "        running_loss += loss_batch.item()\n",
    "        running_metric += metric_batch\n",
    "    test_loss = running_loss / len_data_test\n",
    "    test_metric = running_metric / len_data_test\n",
    "print('test loss: %.6f, test accuracy: %.2f' %(test_loss, 100*test_metric))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyeokjong2",
   "language": "python",
   "name": "hyeikjong2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
